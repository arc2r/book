[["index.html", "All things R Spatial arc2r: An introduction to spatial-R for recovering ArcGIS users 1 What this book is about 1.1 How it started 1.2 What might make your journey difficult 1.3 Why you should transition anyway 1.4 How to use this book", " All things R Spatial arc2r: An introduction to spatial-R for recovering ArcGIS users Nils Ratnaweera and Nikolaos Bakogiannis 1 What this book is about This is a resource for people wanting to learn spatial-R (Analysis, Visualization) in R and are coming with a background in ArcGIS. This resource should provide some help on this journey. We assume you have some prior experience with R. If this is not the case, we recommend you familiarize yourself with R first. We are big fans of using magrittr’s pipe function %&gt;% and heavily use it throughout this book. In addition for vector data, we use packages from the tidyverse (especially filter(), mutate() and summarise().) This book leans heavily on how the Toolboxes and Toolsets are documented in ArcGIS Pro. Is is not a book to read from cover to cover, but to look up specific things of which you only know the ArcGIS terminology for. This book is a work in progress, the current version is from the 2021-02-04 11:02:27 (UTC). We highly appreciate contributions to this book: If you have anything to add, please file an issue or make a pull request. 1.1 How it started We had long since thought about the necessity of a resource which helps ArcGIS users transition to R or Python. Nils had tweeted about this (see below) without getting much reception, and and one point just decided to start his own resource. Since our research group teaches and introduction to GIS and an advanced GIS course mostly based on ArcGIS, we decided to pick up where Nils hat started and develop the resource in with internal funding of our University. Figure 1.1: Nils’ Tweet might not have received much attention, but it did spark a conversation within our group 1.2 What might make your journey difficult What are the main difficulties when switching from ArcGIS to R? The fundamental building block of ArcGIS is a visual representation of your data (i.e. the map). The fundamental building block in R is your RScript. The visual aspect makes ArcGIS more approachable, but also less saleable. When you aquire ArcGIS, you are served from a single source. In R, there are a plethora of developers creating packages for you to use, which can be quite overwhelming while there are always multiple ways to solve a problem in ArcGIS, there are always many more ways to solve it in R When you transition from a proprietary Software like ArcGIS to FOSS, you have to relearn many of the concepts because the proprietary software usually does not adhere to common standards. //todo add this somewhere //body when you add a shapefile to your arcgis project, you basically have a “connection” to this file. in R, you create a virtual copy / an R representation of your dataset within your r session 1.3 Why you should transition anyway We strongly advocate the use of a programming language to tackle GIS tasks for the following reasons: //todo translate this //body add specific advantages of youing FOSS? 1.4 How to use this book //todo add instructions on how to use the book //body details on the arc2r package and the coding environment "],["Data.html", "2 Data", " 2 Data As an ArcGIS user, you are probably very familiar with the two major geodata formats, raster data and vector data. shapefiles and geodatabases with feature classes are most commonly used for vector data in the ESRI World. For raster data, geotiffs and ESRI GRID files inside geodatabases are used very frequently. As you work with OpenSource GIS Tools and Data, you will come across a much richer ecosystem of data formats. //todo add some examples of geodata-formats (gpkg, sqlite) //body link to switchfromshapefile.org In ArcGIS, you add a new dataset to your project using the “Add Data” button in the “Map” Pane. ArcGIS then “helps” you in various ways that R will not. For example, ArcGIS: … only displays files with extensions that are typically associated with geodata (e.g. .tif, .shp etc) … Automatically bundels files multifile-files (files with a common prefix, e.g. shapefiles) and displays it as a single dataset … let’s you visually examine the content of .gdb-files … displays the datatype / geometrytype of a dataset as a little icon … automatically uses the correct mechanisms to import a dataset R provides less help when importing a dataset which can be seen as a disadvantage, but in many cases is more preferable. R interferes less and assumes an informed user who has good knowledge of the data. Just like when importing datasets using read.csv, read.delim and so on, you need to prior knowledge of your data to import it correctly: You need to know the delimiter used to separate columns, and the encoding used to store the information. The same holds true when importing geodata in R: depending on the type of geodata, we need different packages to handle the data and different functions to import it. For handling vector data, the package sf now has replaced its predecessor sp. sf is so powerful and simple, that it has helped bring GIS workflows to non-GIS R users. For handling raster data, the package raster is still in heavy use but is in the process of being replaced by it’s successor, terra. "],["import_vector.html", "2.1 Importing vector data with sf", " 2.1 Importing vector data with sf Most vector data that you use in everyday GIS work are what are called “simple features”. Simple features are an open standard developed by the Open Geospatial Consortium (OGC). The most common feature types are displayed in figure @ref{fig:sf_types}. (#fig:sf_types)The 7 (of 17) most important simple feature types. Image from https://geocompr.robinlovelace.net //todo added reference with bibtex To handle these simple features in R, we need the library sf. library(sf) ## Linking to GEOS 3.8.1, GDAL 3.1.4, PROJ 6.3.1 To import a vector dataset into R, we can use the function read_sf as in the example below. //todo how does the user get access to this dataset? //body make this available through the package? ARE_waedenswil &lt;- read_sf(&quot;sample_data/Entsorgung_Waedenswil/ARE_waedenswil.shp&quot;) ARE_waedenswil ## Simple feature collection with 13 features and 5 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 2689594 ymin: 1228563 xmax: 2694829 ymax: 1234095 ## projected CRS: CH1903+ / LV95 ## [90m# A tibble: 13 x 6[39m ## ID KLASSE KLASSE_DE KLASSE_FR KLASSE_NUM geometry ## [3m[90m&lt;int&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;chr&gt;[39m[23m [3m[90m&lt;dbl&gt;[39m[23m [3m[90m&lt;MULTIPOLYGON [m]&gt;[39m[23m ## [90m 1[39m 69 D D - gering… D - faible… 4 (((2692378 1233048, 2692373 … ## [90m 2[39m [4m1[24m371 D D - gering… D - faible… 4 (((2689720 1232195, 2689767 … ## [90m 3[39m [4m3[24m578 D D - gering… D - faible… 4 (((2692766 1232135, 2692690 … ## [90m 4[39m [4m3[24m591 D D - gering… D - faible… 4 (((2691861 1232707, 2691907 … ## [90m 5[39m [4m3[24m696 A A - sehr g… A - très b… 1 (((2693943 1231286, 2693834 … ## [90m 6[39m [4m3[24m901 B B - gute E… B - bonne … 2 (((2693183 1231097, 2693113 … ## [90m 7[39m [4m4[24m137 B B - gute E… B - bonne … 2 (((2690970 1232339, 2690947 … ## [90m 8[39m [4m4[24m161 B B - gute E… B - bonne … 2 (((2691724 1232478, 2691701 … ## [90m 9[39m [4m4[24m225 B B - gute E… B - bonne … 2 (((2692266 1232198, 2692243 … ## [90m10[39m [4m4[24m401 C C - mittel… C - desser… 3 (((2694681 1230763, 2694659 … ## [90m11[39m [4m5[24m208 C C - mittel… C - desser… 3 (((2693064 1229206, 2693041 … ## [90m12[39m [4m5[24m319 C C - mittel… C - desser… 3 (((2690879 1233702, 2690856 … ## [90m13[39m [4m5[24m514 C C - mittel… C - desser… 3 (((2693168 1229907, 2693145 … And you are done! The shapefile is now imported into your R Session and you can start working with it. Much of the beauty in sf comes from it’s simplicity: As you see from importing the shapefile, it is very much like a data.frame, a structure that you are probably know very well. In fact, it is a data.frame, as you can see here: is.data.frame(ARE_waedenswil) ## [1] TRUE sf provides methods for various generics, e.g. you can use plot() on the object for a simple visualisation. plot(ARE_waedenswil) "],["import_raster_raster.html", "2.2 Importing raster data with raster 2.3 Single band raster 2.4 Multiband Raster", " 2.2 Importing raster data with raster To import raster data, we need a package that can specifically handle raster datasets. The package raster has for a long time been the go-to package for this. However, this package is currently in the process of being replaced with a successor, terra. Since raster is still in heavy use, we will show you how you handle raster data with this package. 2.3 Single band raster Download the sample dataset here and unzip it into your project folder. This dataset is a freely available sample for the swissALTI3D data. The full sample, including files at different resolutions, can be downloaded from here. Now load the library raster the function raster to import the tif-file included in the zip file. Make sure you have set the path to your tif-file correctly. library(raster) ## Loading required package: sp swissalti3d &lt;- raster(&quot;sample_data/swissalti3D/SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196.tif&quot;) ## Warning in showSRID(uprojargs, format = &quot;PROJ&quot;, multiline = &quot;NO&quot;, prefer_proj ## = prefer_proj): Discarded datum Unknown based on Bessel 1841 ellipsoid in Proj4 ## definition The dataset is now imported into your project and ready to be viewed, analysed and processed. If we call the object in our console, we can see that the dataset was imported as a RasterLayer and can see some important statistics which you would typically find via Layer Properties -&gt; Source in ArcGIS. swissalti3d ## class : RasterLayer ## dimensions : 100, 100, 10000 (nrow, ncol, ncell) ## resolution : 10, 10 (x, y) ## extent : 2600000, 2601000, 1196000, 1197000 (xmin, xmax, ymin, ymax) ## crs : +proj=somerc +lat_0=46.9524055555556 +lon_0=7.43958333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +units=m +no_defs ## source : /Users/runner/work/book/book/sample_data/swissalti3D/SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196.tif ## names : SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196 ## values : 623.3814, 858.2705 (min, max) To visualize the dataset, we can simply call plot on our new object. plot(swissalti3d) 2.4 Multiband Raster //todo explain how to import multiband raster "],["import_raster_terra.html", "2.5 Importing raster data with terra", " 2.5 Importing raster data with terra With the terra package, data is imported using the function rast. library(terra) ## terra version 1.0.10 swissalti3d &lt;- terra::rast(&quot;sample_data/swissalti3D/SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196.tif&quot;) Just like before, calling the object in our console will give us the class name and some meta information on the dataset. swissalti3d ## class : SpatRaster ## dimensions : 100, 100, 1 (nrow, ncol, nlyr) ## resolution : 10, 10 (x, y) ## extent : 2600000, 2601000, 1196000, 1197000 (xmin, xmax, ymin, ymax) ## coord. ref. : +proj=somerc +lat_0=46.9524055555556 +lon_0=7.43958333333333 +k_0=1 +x_0=2600000 +y_0=1200000 +ellps=bessel +towgs84=674.374,15.056,405.346,0,0,0,0 +units=m +no_defs ## source : SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196.tif ## name : SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196 ## min value : 623.3814 ## max value : 858.2705 And calling plot on our object visualizes it spatially. plot(swissalti3d) //todo add method for rasters with multiple layers "],["Making_Maps.html", "3 Making Maps", " 3 Making Maps In ArcGIS, the fundamental approach to working with data is through a visual interface. The first thing that happens when you import a dataset into an ArcGIS project is that you get an interactive map visualizing that data. In R on the other hand, when you import a dataset into your project you have only created a connection to that dataset, and may it will be read into your computer’s memory. To visualize your data (which you should do frequently), you need an extra step. This difference between R and ArcGIS is probably what makes ArcGIS so approachable and R so intimidating for beginners. But making a quick visualisation of your geodata is very easy in R, it sometimes just takes a simple line of code. In R, we have to differentiate two different types of outputs: Static maps which can be printed on paper and dynamic maps which you can interact with. Static maps are usually stored in JPG, Tiff of PDF Format which dynamic maps are rendered using html, and javascript. In the beginning, you don’t have to worry about these formats because RStudio automatically displays the maps in the correct pane (“Plot” for static maps and “Viewer” for dynamic maps). A dynamic map is what you get “for free” in ArcGIS within your “Map Window”, a Static map is what you would get when you export a “Layout” to jpg or pdf to use in a report. Prerequisite: Before you start making maps, you will have to familiarize yourself with importing raster or vector data into R. Read chapter Data to get up to speed. "],["Static_Maps.html", "3.1 Static Maps", " 3.1 Static Maps As we saw in chapter Data, we can quickly visualize geodata by simply calling plot on the dataset. library(arc2r) library(sf) ## Linking to GEOS 3.8.1, GDAL 3.1.4, PROJ 6.3.1 library(raster) plot(gemeinde_zh[&quot;bezirksnam&quot;]) plot(swissAlti3D) This is fine for quick view of the data, but as you want to add more layers, legend etc. using base::plot() becomes complicated. There are many alternative methods to visualizing spatial data, we will showcase our favourite methods here. 3.1.1 Package ggplot2 If you are familiar with ggplot2 you can rejoice: Plotting sf objects has become very easy with this package. If you do not know this package yet, we recommend you familiarize yourself with it first before diving into this chapter. We will continue to work with the datasets used above 3.1.1.1 sf objects library(ggplot2) ggplot(gemeinde_zh) + geom_sf() In its most basic form, we can visualize the geometry of our sf object.As always in ggplot2, if you want to use a column from your dataset as an input for, say, colour, you need to specify this with aes(): ggplot(gemeinde_zh) + geom_sf(aes(fill = bezirksnam)) To change the default graticules from WGS84 to a custom Coordinate System, we can use the argument datum in coord_sf and call the EPSG Code of our desired coordinate system. //todo add chapter on CRS //body ArcGIS Users are usually not familiar with ESPG Codes, we should provide an introduction somewhere and reference this here. ggplot(gemeinde_zh) + geom_sf(aes(fill = bezirksnam)) + coord_sf(datum = 2056) How we can use our standard ggplot2 methods to polish this plot: ggplot(gemeinde_zh) + geom_sf(aes(fill = bezirksnam), colour = &quot;white&quot;) + labs(title = &quot;Gemeinden des Kantons Zürich nach Bezirk&quot;,fill = &quot;&quot;) + theme_void() + theme(legend.position = &quot;bottom&quot;) 3.1.1.2 raster objects //todo use a raster object with the same extent as the sf object While sf objects are very easily integrated in ggplot2, raster data is a little harder. There are various ways to plot a raster object with ggplot2. A simple, adhoc approach is converting the RasterLayer object into a data.frame and then plotting it with geom_raster. swissAlti3D_df &lt;- as.data.frame(swissAlti3D,xy = TRUE) # xy = TRUE adds the x and y coordinates to our dataframe as columns # Note the column names of our dataframe head(swissAlti3D_df) ## x y SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196 ## 1 2600005 1196995 673.6359 ## 2 2600015 1196995 673.6822 ## 3 2600025 1196995 674.3226 ## 4 2600035 1196995 675.7197 ## 5 2600045 1196995 679.8717 ## 6 2600055 1196995 684.2903 ggplot(swissAlti3D_df, aes(x, y, fill = SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196)) + geom_raster() Note that this approach, ggplot is not aware of the coordinate system assigned to our dataset. The x and y coordinates from our dataframe are assumed to be in a cartesian coordinate system. This implies two things: This approach only works with datasets in a projected coordinate system (where the raster is assumed to be on a plane) We have to specify that the coordinate system in the two direction are equal with cord_equal() (coord_sf() will not work if we don’t have any sf objects) //todo add example of WGS84 raster ggplot(swissAlti3D_df, aes(x, y, fill = SWISSALTI3D_10_TIFF_CHLV95_LN02_2600_1196)) + geom_raster() + scale_fill_viridis_c() + theme_void() + coord_equal() + theme(legend.position = &quot;bottom&quot;) //todo combine sf and raster //body add an example of how sf and raster can be layered. This needs an additional dataset. 3.1.2 Package tmap While ggplot2 was extended to work with spatial data, the package tmap was specifically designed to create maps. The developer created this package leaning on the “grammar of graphics” approach which is also implemented in ggplot2, so many of the concepts are the same (e.g. the concept of “layers” and using the +-sign). One main difference is that tmap does not use NSE, so column names always need to be quoted. library(tmap) tmap_mode(&quot;plot&quot;) # &lt;- to create static plots ## tmap mode set to plotting tm_shape(gemeinde_zh) + tm_polygons(col = &quot;bezirksnam&quot;) The fact that tmap is designed for maps makes it much easier to add map elements, such as a North Arrow. tm_shape(gemeinde_zh) + tm_polygons(col = &quot;bezirksnam&quot;) + tm_compass() It also means that visualizing a RasterLayer is built in to the package: tm_shape(swissAlti3D) + tm_raster() The most amazing thing about tmap probably is tmap_mode(\"view\"). Run this code and then the two chunks above, you will be amazed. Learn more about this in chapter Interactive Maps. "],["Dynamic_Maps.html", "3.2 Interactive Maps", " 3.2 Interactive Maps As introduced in chapter Making Maps, an interactive Map is the fundamental building block of ArcGIS. In R, we need to do some extra work to create such an interactive map, but this extra work sometimes means just one line of code. There are multiple packages that simplify creating maps: leaflet mapview tmap plotly mapview and tmap both build on the package leaflet, which in turn builds on leaflet, an open source JavaScript Library for interactive maps. There really is not much need to learn leaflet, since using mapview or tmap is much simpler. The package plotly builds on plotly, a very versatile graphics library that provides an API for R, Python and Julia. It is an amazing tool, but we will focus more on mapview and tmap. 3.2.1 Package mapview The package mapview is highly automated and you get a very decent map when calling the function mapview::mapview on your geodata, without any additional arguments. The aim of the package is to be quick and easy, as emphasized in the documentation: It’s main goal is to fill the gap of quick […] interactive plotting to examine and visually investigate both aspects of spatial data, the geometries and their attributes. library(arc2r) library(sf) library(raster) library(mapview) ## GDAL version &gt;= 3.1.0 | setting mapviewOptions(fgb = TRUE) This next line of code generates a representation of your data (in this case, gemeindegrenzen_zh), much like the default map in ArcGIS. mapview(gemeindegrenzen_zh) If the emphasis lies on creating a highly customized map, then tmap may be more appropriate. 3.2.2 Package tmap Like mentioned in the previous chapter, the package tmap facilitates creating highly customized maps. But the greatest strength in tmap comes from it’s versatility: All you need to do is specify how you want your data to be displayed, and tmap can render this into an interactive map of a static one that you can print. All you need to do is change the mode within the function tmap_mode() to view. library(tmap) tmap_mode(&quot;view&quot;) ## tmap mode set to interactive viewing As shown in chapter @ref{static-maps-tmap}, the tmap syntax very similar to ggplot2s, in the sense that connect “layers” using a + sign. tm_shape(gemeindegrenzen_zh) + tm_polygons() This interactive map is very similar to the one generated by mapview, which is not surprising since they are both built on top of leaflet. 3.2.3 Further ressources For more information on tmap, check out the package’s gihub site: https://github.com/mtennekes/tmap For more information on interactive maps in general, head over to the great book “Geocomputation with R”: https://geocompr.robinlovelace.net/adv-map.html#interactive-maps "],["Selection.html", "4 Selection", " 4 Selection A very commonly used tool in ArcGIS is the concept of “Selection”. The idea is, that you select features from your vector dataset in one of the following three ways: Select: Interactively by clicking in your map Select By Attributes: By specifying (non-spatial) criteria based on the attribute table Select By Location: By specifying spatial criteria based on the relationship to another dataset. Figure 4.1: A very commonly used tool: The selection tools from the ArcGIS Pro Map Pane Using the tools via these buttons (@ref{fig:selection}) have two effects. The selected features are highlighted visually Any operation performed with a dataset that has an active selection respects this selection. In other words, the operation is only performed on the selected features. This second effect is cause for many confusing errors, either because the user forgot that a selection was active or the there were zero elements matching the specified criteria and so the operation was performed on an empty dataset. For this reason, this type of “floating selection” is not very useful and was never implemented in R. However, two of the three described methods to select data are supported in R, but with a different approach. The selected data leaves the original data unchanged, but must assigned to a new R object1. Interactive selection (button “Select” in @ref{fig:selection}) is a priori not reproducible and therefore not supported in R. By the way: In the world of SQL this type of operation is not called “selection” but “filtering”. Consequently, that is also the name used in R. In R as well as SQL, a select is done on columns in a dataset, not on rows (i.e. if you want to retain only a subset of the columns in a dataset). or, if you are familiar with pipes, piped into a new operation↩︎ "],["Select_by_Attribute.html", "4.1 Select by Attribute", " 4.1 Select by Attribute //todo does this stay here or move to Analysis -&gt; Extract -&gt; Select? One of the popular approaches in ArcGIS pro for selecting features in a layer is by using an attribute query. The action is performed using the Select By Attributes tool. Select By Attributes tool allows us to provide an SQL query expression to select features that match the selection criteria. R on the other hand offers quite easy and straightforward options to perform similar operations. Let’s examine one of them. As a first step, we might want to import a shapefile. To do so, we can use sf package to work with vector data in R. Important to know is that the rgdal package automatically loads when sf is loaded. In the code snippet below, we read the shapefile, which represents the parking spots for bicycles within the canton of Zurich. The dataset is publicly available for download in the following link: (https://opendata.swiss/en/dataset/veloparkierungsanlagen). library(sf) library(ggplot2) parkBikes &lt;- st_read(&quot;sample_data/Kanton_Zuerich/Veloparkierungsanlagen/OGD_VELOPARKIERANLAGEN_P.shp&quot;) ## Reading layer `OGD_VELOPARKIERANLAGEN_P&#39; from data source `/Users/runner/work/book/book/sample_data/Kanton_Zuerich/Veloparkierungsanlagen/OGD_VELOPARKIERANLAGEN_P.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 511 features and 28 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 2669965 ymin: 1229454 xmax: 2707390 ymax: 1280235 ## projected CRS: CH1903+ / LV95 After importing the dataset, let’s say we want to filter it by selecting only the parking spots that lie within a specific municipality (Gemeinde) in the canton of Zurich. More specifically, we will select only the parking spots within the municipality of Winterthur. For the aforementioned operation, R offers the function filter(), which lies within the dplyr package. This functions works as follows: filter(dataset, condition) library(dplyr) parkBikes_winti &lt;- filter(parkBikes,GEMEINDE == &quot;Winterthur&quot;) The operation above produces the same outcome as the one depicted in the figure below 4.2. Figure 4.2: Select by Attributes in ArcGIS pro "],["Select_by_Location.html", "4.2 Select by Location", " 4.2 Select by Location One of the most commonly used operations in ArcGIS pro is the process of selecting features of a spatial object (layer) based on whether or not these relate spatially to another object (layer). This process is also referred as spatial subsetting. In ArcGIS pro this can be performed in various ways using the Select by Location tool. In R the same operation is, on a first level, performed using the square bracket ([]) operator from the base R package. An example of spatial subsetting could be the following. Let’s assume we have as a shapefile (polygon dataframe) with all the municipalities (Gemeinde) of the Canton of Zurich. Furthermore, we are also using a shapefile in the form of a point dataframe, which represents all the “swimming spots” (Badenplätze) in the same spatial region (Canton of Zurich). So, ultimately, our goal is to find out the “swimming spots” that lie within a specific municipality of the Canton of Zurich. # Minicipalities (Gemeinde) in Canton Zurich gemeinde_ZH &lt;- st_read(&quot;sample_data/Kanton_Zuerich/Gemeinde_ZH.shp&quot;) ## Reading layer `Gemeinde_ZH&#39; from data source `/Users/runner/work/book/book/sample_data/Kanton_Zuerich/Gemeinde_ZH.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 166 features and 7 fields ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: 2669245 ymin: 1223896 xmax: 2716900 ymax: 1283343 ## projected CRS: CH1903+ / LV95 # &quot;Swimming&quot; spots in the Canton of Zurich swimmSpots &lt;- st_read(&quot;sample_data/Kanton_Zuerich/Badeplaetze_ZH.shp&quot;) ## Reading layer `Badeplaetze_ZH&#39; from data source `/Users/runner/work/book/book/sample_data/Kanton_Zuerich/Badeplaetze_ZH.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 71 features and 6 fields ## geometry type: POINT ## dimension: XY ## bbox: xmin: 2671636 ymin: 1226720 xmax: 2710101 ymax: 1282760 ## projected CRS: CH1903+ / LV95 After importing and depicting the “swimming spots” throughout the canton of Zurich, let’s assume we want to check if and how many of them lie within the Municipality of Richterswil. To do so, we will perform an operation, which belongs to the category of Spatial subsetting. swimmSpots_richt &lt;- swimmSpots[richterswil, ,op = st_within] The operation above is based on the following rule: x[y, ,operation], where: x and y are the spatial objects for which we want to investigate if there is a spatial relationship (x is the target feature, while y is the source one) the second argument [, ,] within the brackets denotes the column number we want to retrieve from the spatial subsetting. In our example this argument was empty, which means we wanted to retrieve all rows for every attribute column. the third argument [op = ] specifies the spatial operation we want to perform. In the example above, the goal was to find out how many subset features of the target object swimmSpots lie withing the source spatial object richterswil. For that reason we chose the function st_within(). Depending on what we want to examine, we choose the respective function. "],["Data_Management.html", "5 Data Management Toolbox 5.1 Joins Toolset 5.2 Projections and Transformations Toolset", " 5 Data Management Toolbox Data Management toolbox in ArcGIS pro provides the users a variety of tools for managing, maintaining and developing datasets that come in all possible forms (feature classes / datasets, raster datasets). Below we present all the different options that R offers for performing such operations. 5.1 Joins Toolset In R we have two main options for merging two data frames. On the one hand there is the base R function called merge. The arguments of the merge() function offers the option to perform natural joins. In other words joins such as inner join, left join, right join etc. On the other hand we can come up with similar results by using the join functions that lie within the dplyr package. In the examples below, we choose to use the latter case. Before we begin with our examples, we have to make clear the differences among the various forms of join operations. Natural join or Inner Join reflects on keeping only rows that match from the two data frames. Full outer join or Outer Join reflects on keeping all rows from both data frames. Figure 5.1: Join operations 5.1.1 Inner join Inner Join in R is the most common type of join. It is an operation that returns the rows when the matching condition is fulfilled. Below we demonstrate it with an example. library(dplyr) df1 &lt;- data.frame(TeamID = c(1,4,6,11), TeamName = c(&quot;new york knicks&quot;,&quot;los angeles lakers&quot;,&quot;milwaukee bucks&quot;,&quot;boston celtics&quot;), Championships = c(2,17,1,17)) df2 &lt;- data.frame(TeamID = c(1,2,11,8), TeamName = c(&quot;new york knicks&quot;,&quot;philadelphia 76ers&quot;,&quot;boston celtics&quot;,&quot;los angeles clippers&quot;), Championships = c(2,3,17,0)) df_innerJoin &lt;- df1 %&gt;% inner_join(df2, by = NULL) df_innerJoin ## TeamID TeamName Championships ## 1 1 new york knicks 2 ## 2 11 boston celtics 17 5.1.2 Outer join Outer join in R using simply returns all rows from both data frames. This is very well depicted in 5.1. df_fullJoin &lt;- full_join(df1,df2) df_fullJoin ## TeamID TeamName Championships ## 1 1 new york knicks 2 ## 2 4 los angeles lakers 17 ## 3 6 milwaukee bucks 1 ## 4 11 boston celtics 17 ## 5 2 philadelphia 76ers 3 ## 6 8 los angeles clippers 0 5.1.3 Left / Right join The left join in R returns all records from the data frame on the left, as well as and the matched records from the one at the right. df_leftJoin &lt;- left_join(df1,df2) df_leftJoin ## TeamID TeamName Championships ## 1 1 new york knicks 2 ## 2 4 los angeles lakers 17 ## 3 6 milwaukee bucks 1 ## 4 11 boston celtics 17 Similarly works also the right join. df_rightJoin &lt;- right_join(df1,df2) df_rightJoin ## TeamID TeamName Championships ## 1 1 new york knicks 2 ## 2 11 boston celtics 17 ## 3 2 philadelphia 76ers 3 ## 4 8 los angeles clippers 0 5.2 Projections and Transformations Toolset Quite often in GIS, users found themselves before the necessity of transforming (reprojecting) the coordinate system of a dataset (vector or raster). In fact this is one of the most commonly used operations. In ArcGIS pro the aforementioned action is performed using the following tools: Project (Data Management) -&gt; Projects spatial data from one coordinate system to another. Project Raster (Data Management) -&gt; Transforms a raster dataset from one coordinate system to another. The question now is how we can perform similar operations with R. 5.2.1 Reproject vector data in R For our example we will use the following dataset. bezirke.gpkg -&gt; Dataset that depicts the Municipal structure in Switzerland R and more specifically sf package offers options (functions) not only for transforming the coordinate system of a dataset, but also for identifying the current existing one. Let’s dive in :) # Importing the dataset library(sf) bezirke &lt;- read_sf(&quot;sample_data/other/bezirke.gpkg&quot;) # Visualising the imported dataset library(ggplot2) ggplot() + geom_sf(data = bezirke) In order to identify the current coordinate system of a dataset, sf package offers the function st_crs. The main usage of the function is to retrieve the coordinate reference system from an sf object. # retrieving the coordinate of the imported layer st_crs(bezirke) ## Coordinate Reference System: NA As an output we received that there is no assigned coordinate system to this specific dataset. st_set_crs function helps us assigning a coordinate system to a dataset. # Assigning the World Geodetic System (WGS84) as a coordinate system to our dataset bezirke &lt;- st_set_crs(bezirke, 4326) In the function above, the number 4326 represents the EPSG Geodetic Parameter Dataset (EPSG) of the respective coordinate system. EPSG is a public registry of geodetic datums, spatial reference systems, Earth ellipsoids, coordinate transformations and related units of measurement. st_crs(bezirke) ## Coordinate Reference System: ## User input: EPSG:4326 ## wkt: ## GEOGCRS[&quot;WGS 84&quot;, ## DATUM[&quot;World Geodetic System 1984&quot;, ## ELLIPSOID[&quot;WGS 84&quot;,6378137,298.257223563, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## CS[ellipsoidal,2], ## AXIS[&quot;geodetic latitude (Lat)&quot;,north, ## ORDER[1], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## AXIS[&quot;geodetic longitude (Lon)&quot;,east, ## ORDER[2], ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;World&quot;], ## BBOX[-90,-180,90,180]], ## ID[&quot;EPSG&quot;,4326]] After rerunning the st_crs function, we are getting now that the assigned coordinate system of the dataset is World Geodetic System (WGS84). As a next step, we might want to transform the dataset to the Swiss coordinate system. The respective EPSG for code for the latest Swiss coordinate system (CH1903+LV95) is 2056. For this purpose we use the st_transform function of the sf package. Important &gt; Click to expand! st_set_crs function does not reproject the coordinates of the given dataset. In other words, it does not affect the actual geometry column of the sf object. st_tranform on the other hand indeed does indeed reproject the dataset to another coordinate system. bezirke_swiss &lt;- st_transform(bezirke, 2056) # retrieve the coordinate system st_crs(bezirke_swiss) ## Coordinate Reference System: ## User input: EPSG:2056 ## wkt: ## PROJCRS[&quot;CH1903+ / LV95&quot;, ## BASEGEOGCRS[&quot;CH1903+&quot;, ## DATUM[&quot;CH1903+&quot;, ## ELLIPSOID[&quot;Bessel 1841&quot;,6377397.155,299.1528128, ## LENGTHUNIT[&quot;metre&quot;,1]]], ## PRIMEM[&quot;Greenwich&quot;,0, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433]], ## ID[&quot;EPSG&quot;,4150]], ## CONVERSION[&quot;Swiss Oblique Mercator 1995&quot;, ## METHOD[&quot;Hotine Oblique Mercator (variant B)&quot;, ## ID[&quot;EPSG&quot;,9815]], ## PARAMETER[&quot;Latitude of projection centre&quot;,46.9524055555556, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8811]], ## PARAMETER[&quot;Longitude of projection centre&quot;,7.43958333333333, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8812]], ## PARAMETER[&quot;Azimuth of initial line&quot;,90, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8813]], ## PARAMETER[&quot;Angle from Rectified to Skew Grid&quot;,90, ## ANGLEUNIT[&quot;degree&quot;,0.0174532925199433], ## ID[&quot;EPSG&quot;,8814]], ## PARAMETER[&quot;Scale factor on initial line&quot;,1, ## SCALEUNIT[&quot;unity&quot;,1], ## ID[&quot;EPSG&quot;,8815]], ## PARAMETER[&quot;Easting at projection centre&quot;,2600000, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8816]], ## PARAMETER[&quot;Northing at projection centre&quot;,1200000, ## LENGTHUNIT[&quot;metre&quot;,1], ## ID[&quot;EPSG&quot;,8817]]], ## CS[Cartesian,2], ## AXIS[&quot;(E)&quot;,east, ## ORDER[1], ## LENGTHUNIT[&quot;metre&quot;,1]], ## AXIS[&quot;(N)&quot;,north, ## ORDER[2], ## LENGTHUNIT[&quot;metre&quot;,1]], ## USAGE[ ## SCOPE[&quot;unknown&quot;], ## AREA[&quot;Europe - Liechtenstein and Switzerland&quot;], ## BBOX[45.82,5.96,47.81,10.49]], ## ID[&quot;EPSG&quot;,2056]] 5.2.2 Reproject raster data in R Working with Raster datasets in GIS of operations is of equal importance, as working with vector ones. One of the spatial properties of raster datasets is the the Coordinate Reference System (CRS). CRS is the specific system that “associates” the raster coordinates (which are just pairs of x/y values) to geographic locations. In ArcGIS pro the tool for projecting a raster dataset is called Project Raster (Data Management). Let’s see how we can perform the same operation with R. # Importing the datasets library(raster) # Dataset derived from the spatial interpolation of all the available &quot;recycling points&quot; # in the city of Wädenwil raster_recycling &lt;- raster(&quot;sample_data/Raster/raster_recycling.tif&quot;) # CRS -&gt; CH1903+LV95 # Dataset representing the public transport quality in the city of Wädenswil publicTransport &lt;- raster(&quot;sample_data/Raster/publicTransport_waedi.tif&quot;) # CRS -&gt; WGS84 # Plot the raster dataset - World Geodetic System 1984 plot(publicTransport,las=1, main = &quot;Quality of public transport in the city of Wädenwil - CRS: WGS84&quot;, cex.main=1,font.main=4) We can use the projectRaster() function to reproject a raster into a new CRS. The first argument of the aforementioned function is the raster dataset we want to reproject, while the second one is the dataset to whose projection we are targeting to. So, in our case, we are targeting to the coordinate system of the raster_recycling dataset. It is important to remember that raster reprojection only works when the raster object has already a defined CRS. # Transform the coordinate system of the raster dataset publicTransport_CH # into the Swiss Coordinate system - CH1903+LV95 publicTransport_CH = projectRaster(publicTransport, raster_recycling) # Plot the raster dataset - Swiss Coordinate System CH1903+LV95 plot(publicTransport_CH,las=1, main = &quot;Quality of public transport in the city of Wädenwil - CRS: CH1903+LV95&quot;, cex.main=1,font.main=4) 5.2.3 Generate Tessellation Hexagon Tranverse Hexagon Square Diamond Triangle –&gt; 5.2.3.1 Clip Raster In GIS operations is quite common the necessity of “clipping” an area based on some specific region of interest. This is a quite useful and necessary procedure not only when we are dealing with vector datasets, but also when we have to work with raster ones. In ArcGIS pro the procedure of “cutting” a portion of a raster dataset, mosaic dataset, or an image service layer is performed using Clip Raster tool. In R, the respective operation can be performed using the mask() function. For the example below, we are using the following datasets: ARE_waedi: Vector dataset that depicts the public transport connection quality in the city of Wädenswil raster_recycling: Dataset derived from the spatial interpolation of all the available “recycling points”in the city of Wädenwil # Read raster dataset library(raster) library(stars) library(sf) library(dplyr) library(stars) # Insert a vector dataset that depicts the public transport connection quality in # the city of Wädenswil and plot it ARE_waedi &lt;- read_sf(&quot;sample_data/Entsorgung_Waedenswil/ARE_waedenswil.shp&quot;) # Read the raster dataset and plot it raster_recycling &lt;- raster(&quot;sample_data/Entsorgung_Waedenswil/abfall_raster.tif&quot;) Plot the two datasets one over the other. In our case, the vector dataset serves as the clipping extent for the clipping operation. recycle_Waedi_clip &lt;- mask(raster_recycling,ARE_waedi) Visualising the clipped output "],["Spatial_Analyst.html", "6 Spatial Analyst Toolbox 6.1 Conditional Toolset 6.2 Reclass Toolset 6.3 Surface Toolset", "library(sf) library(tidyverse) library(raster) 6 Spatial Analyst Toolbox 6.1 Conditional Toolset 6.1.1 Kernel Density There are several Function that can be tweaked to calculate KDE for sf-Point object: tmaptools::smooth_map(): Depricated (is there a successor?) spatstat::density.ppp(): Takes only objects of Class ppp MASS::kde2d(): Takes x/y coordinates as vectors and returns a matrix In this example, I take MASS:kde2d() and tweak it to take sf and return raster. First, let’s create some sample data: set.seed(10) mypoints &lt;- data.frame(x = rnorm(1000),y = rnorm(1000)) %&gt;% st_as_sf(coords = c(1,2)) plot(mypoints) my_kde &lt;- function(points,cellsize, bandwith, extent = NULL){ require(MASS) require(raster) require(sf) if(is.null(extent)){ extent_vec &lt;- st_bbox(points)[c(1,3,2,4)] } else{ extent_vec &lt;- st_bbox(extent)[c(1,3,2,4)] } n_y &lt;- ceiling((extent_vec[4]-extent_vec[3])/cellsize) n_x &lt;- ceiling((extent_vec[2]-extent_vec[1])/cellsize) extent_vec[2] &lt;- extent_vec[1]+(n_x*cellsize)-cellsize extent_vec[4] &lt;- extent_vec[3]+(n_y*cellsize)-cellsize coords &lt;- st_coordinates(points) matrix &lt;- kde2d(coords[,1],coords[,2],h = bandwith,n = c(n_x,n_y),lims = extent_vec) raster(matrix) } mypoints_kde &lt;- my_kde(mypoints,0.01,1) library(stars) ggplot() + geom_stars(data = st_as_stars(mypoints_kde)) + geom_sf(data = mypoints, alpha = 0.2, fill = &quot;black&quot;) + scale_fill_viridis_c() + labs(fill = &quot;KDE&quot;) + theme_void() 6.2 Reclass Toolset 6.3 Surface Toolset 6.3.1 Slope and Aspect In mathematics, the slope or gradient of a line describes its steepness, incline, or grade. A higher slope value indicates a steeper incl. Source: “http://wiki.gis.com/wiki/index.php/Slope” In GIS and specifically in terrain analysis, calculating the terrain slope is of great importance, since it can play a significant role in various forms of technical analysis. The most common way of calculating the slope is from a Digital Elevation Model (DEM). In ArcGIS pro the tool used for computing the slope of a raster dataset with elevation data is called Slope (3D Analyst).It identifies the steepness at each cell of a raster surface. The lower the slope value, the flatter the terrain; the higher the slope value, the steeper the terrain. In R, raster package includes the function terrain(), which helps us compute slope, aspect and other terrain characteristics from a raster with elevation data. Let’s start by computing the slope of the swissAlti3d raster dataset. # Importing a raster dataset # swissALTI3D2019.tif -- Source: https://geovite.ethz.ch library(raster) swissAlti3d &lt;- raster(&quot;sample_data/Raster/swissALTI3D2019.tif&quot;) plot(swissAlti3d, main = &quot;swissALTI3D2019 - CRS: CH1903+LV95&quot;, cex.main=1,font.main=4) After importing and visualizing our raster dataset, we use the terrain function to calculate the slope. # Computing the slope of a raster dataset using the terrain() function swissAlti3d_slope &lt;- terrain(swissAlti3d, opt=&quot;slope&quot;, unit=&quot;degrees&quot;) plot(swissAlti3d_slope, main = &quot;Slope of swissALTI3D2019 in degrees (°)&quot;, cex.main=1,font.main=4) In the function above, we define the operation we want to perform as the second argument of the function (opt = “slope”). Furthermore, we also define the units of the final result. Similarly, we compute the aspect of a given dataset. Basically as aspect we can consider the compass direction that a slope leans towards. Let’s compute now, using again the same function terrain, the aspect of the same dataset swissALTI3D2019. # Computing the aspect of the terrain dataset swissAlti3d_aspect &lt;- terrain(swissAlti3d, opt=&quot;aspect&quot;, unit=&quot;degrees&quot;) plot(swissAlti3d_aspect, main = &quot;Aspect of swissALTI3D2019 in degrees (°)&quot;, cex.main=1,font.main=4) So, R gives us the option to retrieve multiple terrain characteristics of a raster dataset, using only one function. The aforementioned spatial operation in ArcGIS pro could be performed using the tool Aspect (Spatial Analyst). 6.3.2 Reclassify In GIS quite often arises the necessity to reclassify a raster dataset. In other words, to create new classes with different range of values for the existing cell values of the dataset. This operation in ArcGIS Pro is performed using the Reclassify (Spatial Analyst) tool. In R the respective operation is quite straightforward and is based on the use of the reclassify function of the raster package. For our example we use the raster dataset we computed previously, which depicts the aspect of the swissALTI3D2019 dataset. As a first step, we can compute the histogram of our dataset. summary(swissAlti3d_aspect) ## aspect ## Min. 0.0000 ## 1st Qu. 104.1014 ## Median 163.3606 ## 3rd Qu. 258.6777 ## Max. 359.9991 ## NA&#39;s 12652.0000 histinfo &lt;- hist(swissAlti3d_aspect) histinfo$breaks ## [1] 0 20 40 60 80 100 120 140 160 180 200 220 240 260 280 300 320 340 360 The number of breaks for our raster values are 19. The aim of ours is to create 4 different classes with the following values: 0°-90° -&gt; Class 1 90°-180° -&gt; Class 2 180°-270° -&gt; Class 3 270°-360° -&gt; Class 4 To do so, we create below a reclassification matrix with the respective values. # create a reclassification matrix reclass_df &lt;- c(0,90,1,90,180,2,180,270,3,270,360,4) # convert to Matrix reclass_m &lt;- matrix(reclass_df, ncol = 3, byrow = TRUE) reclass_m ## [,1] [,2] [,3] ## [1,] 0 90 1 ## [2,] 90 180 2 ## [3,] 180 270 3 ## [4,] 270 360 4 After creating the respective matrix with the new classes, we are ready to call the reclassify function. The function takes as a first argument the dataset set to be reclassified and as second the matrix, on which the reclassification is based on. swissAlti3d_aspect_reclass &lt;- reclassify(swissAlti3d_aspect, reclass_m) plot(swissAlti3d_aspect_reclass, col = c(&quot;red&quot;, &quot;green&quot;, &quot;yellow&quot;,&quot;blue&quot;), main = &quot;Aspect of swissALTI3D2019 in 4 classes&quot;, cex.main=1,font.main=4, legend = FALSE) legend(&quot;topright&quot;, legend = c(&quot;0°-90°&quot;, &quot;90°-180°&quot;, &quot;180°-270°&quot;,&quot;270°-360°&quot;), fill = c(&quot;red&quot;, &quot;blue&quot;, &quot;green&quot;, &quot;yellow&quot;), border = FALSE, bty = &quot;n&quot;) # turn off legend border "],["3D_Analyst.html", "7 3D Analyst Toolbox 7.1 Raster Interpolation Toolset", " 7 3D Analyst Toolbox 7.1 Raster Interpolation Toolset library(sp) library(sf) library(tidyverse) library(stars) data(meuse) meuse_sf &lt;- meuse %&gt;% st_as_sf(coords = c(&quot;x&quot;,&quot;y&quot;)) 7.1.1 IDW my_idw &lt;- function(groundtruth,column,cellsize, nmax = Inf, maxdist = Inf, idp = 2, extent = NULL){ require(gstat) require(sf) require(raster) if(is.null(extent)){ extent &lt;- groundtruth } samples &lt;- st_make_grid(extent,cellsize,what = &quot;centers&quot;) %&gt;% st_as_sf() my_formula &lt;- formula(paste(column,&quot;~1&quot;)) idw_sf &lt;- gstat::idw(formula = my_formula,groundtruth,newdata = samples,nmin = 1, maxdist = maxdist, idp = idp) idw_matrix &lt;- cbind(st_coordinates(idw_sf),idw_sf$var1.pred) ras &lt;- raster::rasterFromXYZ(idw_matrix) if(all(grepl(&quot;polygon&quot;,st_geometry_type(extent),ignore.case = TRUE))){ ras &lt;- raster::mask(ras,st_as_sf(st_zm(extent))) } ras } meuse_idw &lt;- my_idw(meuse_sf,&quot;copper&quot;,cellsize = 10,idp = 3) ## [inverse distance weighted interpolation] ggplot() + geom_stars(data = st_as_stars(meuse_idw)) + scale_fill_viridis_c() + theme_void() + labs(fill = &quot;copper&quot;) + coord_equal() 7.1.2 Kriging my_krige &lt;- function(groundtruth,column,cellsize, nmax = Inf, maxdist = Inf, extent = NULL){ require(gstat) require(sf) require(raster) if(is.null(extent)){ extent &lt;- groundtruth } samples &lt;- st_make_grid(extent,cellsize,what = &quot;centers&quot;) %&gt;% st_as_sf() my_formula &lt;- formula(paste(column,&quot;~1&quot;)) idw_sf &lt;- gstat::krige(formula = my_formula,groundtruth,newdata = samples,nmin = 1, maxdist = maxdist) idw_matrix &lt;- cbind(st_coordinates(idw_sf),idw_sf$var1.pred) ras &lt;- raster::rasterFromXYZ(idw_matrix) if(all(grepl(&quot;polygon&quot;,st_geometry_type(extent),ignore.case = TRUE))){ ras &lt;- raster::mask(ras,st_as_sf(st_zm(extent))) } ras } meuse_krige &lt;- my_krige(meuse_sf,&quot;copper&quot;,cellsize = 10,nmax = 30, maxdist = 500) ## [inverse distance weighted interpolation] ggplot() + geom_stars(data = st_as_stars(meuse_krige)) + scale_fill_viridis_c(na.value = NA) + theme_void() + labs(fill = &quot;copper&quot;) + coord_equal() 7.1.3 Natural Neighbor Nearest Neighbor: meuse_thiessen &lt;- st_voronoi(st_union(meuse_sf)) meuse_thiessen &lt;- st_cast(meuse_thiessen) meuse_bbox &lt;- meuse_sf %&gt;% st_bbox() %&gt;% st_as_sfc() meuse_thiessen &lt;- st_intersection(meuse_thiessen,meuse_bbox) meuse_thiessen &lt;- st_as_sf(meuse_thiessen) meuse_thiessen &lt;- st_join(meuse_thiessen,meuse_sf) ggplot() + geom_sf(data = meuse_thiessen, aes(fill = copper)) + geom_sf(data = meuse_sf) + scale_fill_viridis_c() + theme_void() "],["Image_Analysis.html", "8 Image Analysis Toolbox 8.1 Map Algebra Toolset", " 8 Image Analysis Toolbox 8.1 Map Algebra Toolset 8.1.1 Raster Calulator In GIS Softwares (ArcGIS pro, QGIS etc) Raster Calculator is one of the most commonly used tools for performing various operations with raster datasets. For the example below we will work with 2 datasets that depict India’s population at two different timestamps. Our goal is to produce an output raster that demonstrates the evolvement of country’s population in this 10 years timespan. Naturally in ArcGIS pro, the aforementioned operation would be performed with the use of Raster Calculator. Let’s explore our options with R. # Read the data for our example library(raster) # India&#39;s population in 2000 india_2000 &lt;- raster(&quot;sample_data/population_raster/india_2000.tif&quot;) # India&#39;s population in 2010 india_2010 &lt;- raster(&quot;sample_data/population_raster/india_2010.tif&quot;) par(mfrow=c(1,2)) plot(india_2000) plot(india_2010) Let’s compute now the difference between the two rasters. To do so, there are various options. As first we can create a function that performs a simple subtraction of two rasters. diff_rasters &lt;- function(b1, b2){ # this function calculates the difference between two rasters of the same CRS and extent # input: 2 raster layers of the same extent, crs that can be subtracted # output: a single different raster of the same extent, crs of the input rasters diff &lt;- b2 - b1 return(diff) } Since, we created the function for subtracting one raster from another, we use now the function overlay of the raster package for producing the new raster output. # Compute the raster that depicts the difference in population in these 10 years pop2010_2000 &lt;- overlay(india_2000, india_2010, fun = diff_rasters) plot(pop2010_2000, main = &quot;India&#39;s population difference in the timespan of 10 years&quot;, cex.main = 1) 8.1.2 Focal Statistics 8.1.3 Zonal Statistics Focal statistics performs a neighbourhood operation that computes an output raster, where the value for each output cell is a function of the values of all the input cells that are in a specified neighborhood around that location. The function performed on the input is a statistic, such as the maximum, average, or sum of all values encountered in that neighborhood. Source: https://pro.arcgis.com/en/pro-app/latest/tool-reference/spatial-analyst/how-focal-statistics-works.html In R in order to apply functions focally to rasters, important is to define the neighbouring cells. In other words to define the moving window for each of these functions. As an example below, we will create our own raster object. library(raster) r &lt;- raster(ncol=10, nrow=10) values(r) &lt;- 1:ncell(r) plot(r, main=&#39;Raster with 100 cells&#39;, cex.main = 1) We will recompute now the raster based on the focal function of the raster package. In the function below, the neighbourhood for which we apply the statistic is represented by the argument w, while the statistic by the argument fun. f1 &lt;- focal(r, w=matrix(1,nrow=3,ncol=3),fun=sum) plot(f1, main = &quot;Raster after applying the focal function - raster package&quot;, cex.main = 1) The operation above can be also performed with the use of the focal function of the terra package. w represents the moving window of the function. The window can be defined as one (for a square) or two numbers (row, col); or with an odd-sized weights matrix. More details can be found here: https://rdrr.io/cran/terra/man/focal.html fun represents the specified statistic for the identified neighbourhood (e.g mean,sum etc) library(terra) r_spat &lt;- as(r, &quot;SpatRaster&quot;) f2 &lt;- terra::focal(r_spat,w=3,fun = &quot;sum&quot;) plot(f2, main = &quot;Raster after applying the focal function - terra package&quot;, cex.main = 1) 8.1.4 Zonal Statistics Zonal Statistics tool in ArcGIS pro is used for calculating the statistics on values of a raster within the zones of another dataset. In R we are able to produce similar results with the use of zonal function of the raster package. r &lt;- raster(ncols=10, nrows=10) # generating random numbers that will used as values in our raster layer (r) - input values raster values(r) &lt;- runif(ncell(r)) * 1:ncell(r) z &lt;- r # generating integer values for the raster layer z, which will be used as the zone raster values(z) &lt;- rep(1:5, each=20) # Zonal statistics - Summarize zonal(r, z, &quot;sum&quot;) ## zone sum ## [1,] 1 99.58052 ## [2,] 2 305.81367 ## [3,] 3 475.71375 ## [4,] 4 707.51735 ## [5,] 5 796.50114 # Zonal statistics - Mean zonal(r, z, &quot;mean&quot;) ## zone mean ## [1,] 1 4.979026 ## [2,] 2 15.290684 ## [3,] 3 23.785688 ## [4,] 4 35.375867 ## [5,] 5 39.825057 # Zonal statistics - Minimum zonal(r, z, &quot;min&quot;) ## zone min ## [1,] 1 0.1487266 ## [2,] 2 1.9187318 ## [3,] 3 3.1954170 ## [4,] 4 4.5574448 ## [5,] 5 2.8274044 "],["Analysis.html", "9 Analysis Toolbox 9.1 Clip 9.2 Merge 9.3 Spatial Join 9.4 Buffer", " 9 Analysis Toolbox 9.1 Clip Quite often in spatial analysis, we come across with cases, where we do not want to use all the available data there is. In other words, we want to focus on a specific area of interest, which dictates the need for clipping the existing dataset based on it’s relationship to some other existing spatial feature. In R this operation can be easily performed using the st_intersection function in sf. Let’s assume in the example below that we want to clip the available dataset of all the train stations in Switzerland by focusing our analysis on four specific cantons. library(sf) # Point dataset depicting the train stations locations across Switzerland bahn_haltestelle_ch &lt;- st_read(&quot;sample_data/other/Haltestelle_Bahn_CH.shp&quot;) ## Reading layer `Haltestelle_Bahn_CH&#39; from data source `/Users/runner/work/book/book/sample_data/other/Haltestelle_Bahn_CH.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 3134 features and 16 fields ## geometry type: POINT ## dimension: XYZ ## bbox: xmin: 2488908 ymin: 1076850 xmax: 2817389 ymax: 1289090 ## z_range: zmin: 194.905 zmax: 3453.525 ## projected CRS: CH1903+ / LV95 # Dataset depicting Switzerland on canton level kantonsgebiet &lt;- st_read(&quot;sample_data/other/Kantonsgebiet.shp&quot;) ## Reading layer `Kantonsgebiet&#39; from data source `/Users/runner/work/book/book/sample_data/other/Kantonsgebiet.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 56 features and 22 fields ## geometry type: MULTIPOLYGON ## dimension: XYZ ## bbox: xmin: 2485410 ymin: 1075268 xmax: 2833858 ymax: 1295934 ## z_range: zmin: 193.51 zmax: 4613.729 ## projected CRS: CH1903+ / LV95 tmap_mode(mode = c(&quot;plot&quot;)) # setting the plotting mode to static -- optimizing the process tm_shape(kantonsgebiet) + tm_polygons(&quot;#f0f0f0&quot;) + tm_shape(bahn_haltestelle_ch) + tm_dots(col = &quot;#e34a33&quot;,size = 0.1, alpha = 0.5) + tm_shape(kantonsgebiet) + tm_borders(col = &quot;black&quot;) + tm_layout(frame = F) As it was mentioned above, the aim is to analyse the situation at a particular area. So we are going to create an index with the specific cantons we are interested in. index &lt;- kantonsgebiet$name == &quot;Zürich&quot; | kantonsgebiet$name == &quot;St. Gallen&quot; | kantonsgebiet$name == &quot;Thurgau&quot; | kantonsgebiet$name == &quot;Aargau&quot; # Selecting the cantons based on the previously generated index kantons_aOi &lt;- kantonsgebiet[index,] # Performing the clipping operation hal_clipped &lt;- st_intersection(kantons_aOi,bahn_haltestelle_ch) Plotting the result from the clipping operation tm_shape(kantons_aOi) + tm_polygons(&quot;#f0f0f0&quot;) + tm_shape(hal_clipped) + tm_dots(col = &quot;#e34a33&quot;,size = 0.1, alpha = 0.5) + tm_shape(kantons_aOi) + tm_borders() + tm_layout(frame = F) So, ultimately, as we can see above, the st_intersection function creates a result where the point dataset is precisely “clipped” based on the area of interest The operation above produces the same outcome as the one depicted in the figure below ??. Figure 9.1: Clip operation in ArcGIS pro 9.2 Merge Let’s assume in the example below that instead of having four individual areas of interest, we are interested in having one common, unified area on which we focus our analysis. In other words, we have to merge the existing four areas into one. In ArcGIS pro the respective tools for this action is either the Merge or the Dissolve tool. In R on the other hand, this can be easily performed using the st_union function in the sf package. # The area of interest from the previous example - section Clip head(kantons_aOi) ## Simple feature collection with 6 features and 22 fields ## geometry type: MULTIPOLYGON ## dimension: XYZ ## bbox: xmin: 2620698 ymin: 1193269 xmax: 2768769 ymax: 1283504 ## z_range: zmin: 260.666 zmax: 3246.858 ## projected CRS: CH1903+ / LV95 ## uuid datum_aend datum_erst erstellung ## 6 {05D55405-466B-4ECC-83C7-A906DEB0D607} 2017-12-04 2012-10-26 2012 ## 7 {FB7105B8-6D7C-4787-846E-17B2BC145C6E} 2018-11-22 2012-10-26 2012 ## 10 {E11CD2CA-2E2D-415C-8789-C10D7C26E441} 2016-12-09 2012-10-26 2012 ## 12 {87370D3F-DBBE-4D05-AF85-C358C3924B3D} 2018-11-22 2012-10-26 2012 ## 41 {99488953-65F6-4F86-8606-337113587F85} 2015-12-08 2012-10-26 2012 ## 47 {F1A07951-AC8B-4EBA-B48F-64BC8B92228C} 2015-12-08 2012-10-26 2012 ## erstellu_1 revision_j revision_m grund_aend herkunft herkunft_j herkunft_m ## 6 10 2019 1 400 100 2018 1 ## 7 10 2019 1 400 500 2019 1 ## 10 10 2019 1 400 100 2017 1 ## 12 10 2019 1 400 500 2019 1 ## 41 10 2019 1 400 500 2015 12 ## 47 10 2019 1 400 500 2015 12 ## objektart kantonsnum see_flaech revision_q kantonsfla kanton_tei name ## 6 0 17 7720 2018_Aufbau 202820 1 St. Gallen ## 7 0 1 6811 2018_Aufbau 172894 0 Zürich ## 10 0 19 870 2018_Aufbau 140380 1 Aargau ## 12 0 20 13121 2018_Aufbau 99433 1 Thurgau ## 41 0 20 0 2018_Aufbau 0 2 Thurgau ## 47 0 17 0 2018_Aufbau 0 2 St. Gallen ## icc einwohnerz Shape_Leng Shape_Area geometry ## 6 CH 504686 494074.195 2028094302.5 MULTIPOLYGON Z (((2703763 1... ## 7 CH 1504346 312972.523 1728941805.8 MULTIPOLYGON Z (((2673542 1... ## 10 CH 670988 328943.352 1403783344.8 MULTIPOLYGON Z (((2673542 1... ## 12 CH 273801 287778.920 990592017.5 MULTIPOLYGON Z (((2701937 1... ## 41 CH 0 8640.269 3737271.5 MULTIPOLYGON Z (((2751489 1... ## 47 CH 0 1481.811 105406.8 MULTIPOLYGON Z (((2744263 1... # Merging the four areas into one aOi_merged &lt;- st_union(kantons_aOi) Plot the merged area of interest tm_shape(aOi_merged) + tm_polygons(&quot;#f0f0f0&quot;) + tm_layout(frame = F) The operation above produces the same outcome as the one depicted in the figure below ??. Figure 9.2: Dissolve operation in ArcGIS pro 9.3 Spatial Join Say you have two datasets: library(sf) library(tidyverse) zweitwohnung &lt;- read_sf(&quot;sample_data/other/zweitwohnung_gemeinden.gpkg&quot;) %&gt;% dplyr::filter(kanton == &quot;Valais / Wallis&quot;) %&gt;% select(NAME) bbox &lt;- st_bbox(zweitwohnung) %&gt;% st_as_sfc() points &lt;- st_sample(bbox,500) ggplot(zweitwohnung) + geom_sf() + geom_sf(data = points) In R, the function used to join two datastes is st_join(x,y). If you have to different data types (e.g. Points and Polygons) the first question you have to ask yourself is: what data type should the output be? The datatype of x determins what the output datatype is. So with the above data: Say for each point, we want to know the Name (NAME) of the “Geimeinde” in which it lies. This means the output is a point dataset. We therefore write: st_join(st_sf(points),zweitwohnung,join = st_within) Note that points not located in a Gemeinde get the value NA. You have to specify the spatial relationship of your join method within the argument join =. This argument take a so called spatial predicate function. From the join_methods available in ArcGIS, here’s the equivalant spatial predicate function: ArcGIS Term R Spatial Predicate Intersect st_intersect Intersect 3D (1) Within a distance st_is_within_distance Within a distance geodesic ?? Within a distance 3D (1) Contains st_contains Completely contains st_contains_properly? Contains clementini ?? Within st_within Completely within Within clementini ?? Are identical to st_equals? boundry touches st_touches Share a line segment Have their center in Closest st_nearest_feature? Closest geodesic ?? All binary predicates only work on 2D Objects (see this issue) 9.4 Buffer One of the most commonly used operations in ArcGIS pro is the one called Buffer. This operation provides a very convenient way of identifying areas of interest lying in the neighborhood of an existing spatial feature. In R the same action can be performed using the st_buffer function in sf. Below we introduce a line spatial feature that depicts all the mountain bike routes in Switzerland. ## Reading layer `mountainBikes_routes&#39; from data source `/Users/runner/work/book/book/sample_data/other/mountainBikes_routes.shp&#39; using driver `ESRI Shapefile&#39; ## Simple feature collection with 286 features and 29 fields ## geometry type: LINESTRING ## dimension: XYZ ## bbox: xmin: 2497570 ymin: 1077136 xmax: 2836678 ymax: 1296227 ## z_range: zmin: 197.367 zmax: 2860.725 ## projected CRS: CH1903+ / LV95 We focus, as an area of interest, on the canton of Valais. Consequently, we might be interested in identifying all the areas in a radius of 1000 m around these bike routes. Selecting the canton of Valais Apply a buffer of 1000m on each of the mountain bike routes within the canton of Valais routes_buffer &lt;- st_buffer(mountainBikes_routes_valais,1000) tm_shape(canton_valais) + tm_polygons() + tm_shape(mountainBikes_routes_valais) + tm_lines(col = &quot;#e34a33&quot;) + tm_shape(routes_buffer) + tm_polygons(col = &quot;blue&quot;, alpha = 0.2) + tm_shape(canton_valais) + tm_borders(col = &quot;black&quot;) + tm_layout(frame = F) The operation above produces the same outcome as the one depicted in the figure below ??. Figure 9.3: Buffer operation in ArcGIS pro "],["Chapter_overview.html", "10 Topology Rules", " 10 Topology Rules in ArcGIS, you create a topology rule by first creating a Feature Dataset in a Geodatabase, and then adding one or more Topology Rules to that Feature Dataset. In R, you can check topology using the DE-9IM together with st_relate(). "],["Polygon.html", "10.1 Polygon", " 10.1 Polygon 10.1.1 Must not overlap In context of DE-9IM, this is a simple case. The polygon interiors should not overlap at all, everything else does not matter. Interior-Interior is the first of the 9 intersections, so the the intersection matrix as a code string would be: 2********. In the case of the example below: set.seed(10) nrows &lt;- 10 circs &lt;- data.frame( id = 1:nrows, x = rnorm(nrows), y = rnorm(nrows) ) %&gt;% st_as_sf(coords = c(2,3)) %&gt;% st_buffer(0.25) circsplot &lt;- ggplot(circs) + geom_sf(fill = &quot;blue&quot;,alpha = 0.3) + geom_sf_text(aes(label = id)) + theme_void() circsplot This gives us a sparse matrix as an output, which is esentially a list with the same length as the x, where each position is a vector of integers with the indicies of the features in y (which may equal to x) where the pattern matches. st_relate(circs,pattern = &quot;2********&quot;) ## Sparse geometry binary predicate list of length 10, where the predicate was `relate_pattern&#39; ## 1: 1, 2, 5 ## 2: 1, 2, 4, 5, 10 ## 3: 3 ## 4: 2, 4 ## 5: 1, 2, 5 ## 6: 6 ## 7: 7 ## 8: 8 ## 9: 9 ## 10: 2, 10 Setting sparse = FALSE returns a crossmatrix of all combinations.W crossmatrix &lt;- st_relate(circs,pattern = &quot;2********&quot;,sparse = FALSE) crossmatrix[1:6,1:6] # only showing 6 since this prints nicely ## [,1] [,2] [,3] [,4] [,5] [,6] ## [1,] TRUE TRUE FALSE FALSE TRUE FALSE ## [2,] TRUE TRUE FALSE TRUE TRUE FALSE ## [3,] FALSE FALSE TRUE FALSE FALSE FALSE ## [4,] FALSE TRUE FALSE TRUE FALSE FALSE ## [5,] TRUE TRUE FALSE FALSE TRUE FALSE ## [6,] FALSE FALSE FALSE FALSE FALSE TRUE # Remove the diagonals since it&#39;s simply each feature tested against itself diag(crossmatrix) &lt;- FALSE error &lt;- which(crossmatrix,arr.ind = TRUE) %&gt;% as.vector() %&gt;% unique() circsplot + geom_sf(data = circs[error,], fill = &quot;red&quot;, alpha = 0.3) 10.1.2 Must not have gaps Lets cosider the North Carolina Dataset for this question. nc = st_read(system.file(&quot;shape/nc.shp&quot;, package=&quot;sf&quot;), quiet = TRUE) ggplot(nc) + geom_sf() + theme_void() The first task is to dissolve all adjecent polygons together nc_union &lt;- st_union(nc) nc_union ## Geometry set for 1 feature ## geometry type: MULTIPOLYGON ## dimension: XY ## bbox: xmin: -84.32385 ymin: 33.88199 xmax: -75.45698 ymax: 36.58965 ## geographic CRS: NAD27 If the output is a multipolygon as it is the case here, it’s bad news, there are gaps. To check which parts are disconnected from each other, we can cast the multipolygon to a polygon (in ArcGIS Terms “Multipart to singlepart”), add a rowname for each part and colour it by rowname. nc_singlepart &lt;- nc_union %&gt;% st_cast(&quot;POLYGON&quot;)%&gt;% st_sf() %&gt;% mutate(id = 1:n()) ggplot(nc_singlepart) + geom_sf(aes(fill = factor(id))) + labs(fill = &quot;id&quot;) + theme_void() But maybe we can live with these Islands in the state of North Carolina, since this is in fact an accurate representation of reality (the gaps are a result of the Atlantic Ocean). We must now check whether the individual geometries have holes. Here we can make use of the way polygons are defined in sf: geometry with a positive area (two-dimensional); sequence of points form a closed, non-self intersecting ring; the first ring denotes the exterior ring, zero or more subsequent rings denote holes in this exterior ring This means that the length of each Polygon geometry must be 1. A length of 2 or more would mean that there are one (or more) holes in the geometry. We can do this with any of the functions from the apply family, I prefer purrr: map_lgl(nc_singlepart$geometry,~length(.x)== 1) ## [1] TRUE TRUE TRUE TRUE TRUE TRUE Let’s see what happens if we cut a hole into the polygons holes &lt;- nc_singlepart %&gt;% st_union() %&gt;% st_centroid() %&gt;% st_buffer(0.5) nc_holes &lt;- st_difference(nc_singlepart,holes) ggplot(nc_holes) + geom_sf() + theme_void() map_lgl(nc_holes$geometry,~length(.x)== 1) ## [1] FALSE TRUE TRUE TRUE TRUE TRUE 10.1.3 Contains point 10.1.4 Contains one Point 10.1.5 Must be covered by feature class of 10.1.6 Boundary must be covered by 10.1.7 Must not overlap with 10.1.8 Must be covered by 10.1.9 Area boundary must be covered by boundary of 10.1.10 Must cover each other "]]
